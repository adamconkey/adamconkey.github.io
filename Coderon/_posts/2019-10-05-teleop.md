---
layout: post
title: Teleoperation in Virtual Environments with Haptic Feedback
description: 
date: 2019-10-05
image: '/images/teleop_cover.png'
video_embed: 'https://www.youtube.com/embed/PLEuahvvX5o?si=_M1LodMV0atjzope'
tags: [Teleoperation]
tags_color: '#32a852'
featured: true
---

This was a project I worked on extensively at the start of my PhD and built out infrastructure for over the course of about 3 years. Unfortunately, the project never got fully funded so I didn't get to see it through to fruition. But I developed some cool software for it and want to show it off!

## Teleoperation in Virtual Environments

Teleoperation is a common robot control paradigm where a human user commands a robot using an input device. The input device could be as simple as keyboard button presses, and as advanced as a specially designed control mechanism or even another robot moved about in gravity compensation mode. This is in contrast to a robot operating autonomously where it is deciding its own actions and executing motions without human direction. Teleoperation is common for recording data that can be used to learn autonomous policies from. It is also common for simply having a robot controlled by a human, e.g. operating a rescue robot at a disaster site.

I was exploring a project where policy learning could be done in a virtual simulation environment. The basic idea was a human user could teleoperate a virtual robot in a virtual environment, and learn a policy that could then be deployed to a real robot in a real environment. The kicker is we wanted to incorporate force feedback in the virtual environment, so that we could learn force-aware policies to deploy to the real robot, in hopes of learning more robust policies that could account for interaction forces in the environment. 

To achieve this, we wanted a way to physcially render force feedback to the user as they engage with the virtual environment. We decided to use a [Phantom Omni](https://delfthapticslab.nl/device/phantom-omni/) haptic input device. This enabled the user to move a stylus around in 3D and feel force resistance from the device. The challenge for me was to figure out how to compute forces in the virtual world, and how to render them to the user within a framework for policy learning and deployment. I'll go into some of the more interesting details below.


***

## Software Development


| Repository | Description |
|------------|-------------|
| [ll4ma_teleop](https://bitbucket.org/robot-learning/ll4ma_teleop/src/master/) | Package for teleoperating virtual and real robots with haptic input devices, including sending commands, rendering virtual environments, and an rviz plugin. |
| [phantom_omni](https://bitbucket.org/robot-learning/phantom_omni/src/main/) | A fork of [fsuarez6/phantom_omni](https://github.com/fsuarez6/phantom_omni) where I had to make several URDF modifications and some driver modifications to get our device working in the lab. |
| [dart_ros](https://bitbucket.org/robot-learning/dart_ros/src/master/) | A package I developed to use a [DART](https://dartsim.github.io) simulation physics backend to compute physics for a simulator interface in rviz. |

---

### Virtual Environment

I wanted a relatively lightweight simulation environment where I could have some control over force rendering, as we were planning on experimenting with different approaches for that. I opted to use rviz as a visual renderer of the scene, primarily because I was already experienced with it and it had all of the basic visualizations and plugin interfaces we needed. I chose to use [DART](https://dartsim.github.io) as the backend physics engine, as it had proven to be the superior physics engine in Gazebo for contact dynamics in manipulation tasks. Note, this was before the proliferation of better physics simulators for robotics like NVIDIA Isaac and friends.

