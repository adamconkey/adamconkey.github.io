<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Sensors | Adam Conkey</title>
    <link>https://adamconkey.github.io/tag/sensors/</link>
      <atom:link href="https://adamconkey.github.io/tag/sensors/index.xml" rel="self" type="application/rss+xml" />
    <description>Sensors</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 05 Oct 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://adamconkey.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Sensors</title>
      <link>https://adamconkey.github.io/tag/sensors/</link>
    </image>
    
    <item>
      <title>ReFlex TakkTile in Gazebo Simulation</title>
      <link>https://adamconkey.github.io/project/reflex_sensors/</link>
      <pubDate>Sat, 05 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://adamconkey.github.io/project/reflex_sensors/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve done some work to get the &lt;a href=&#34;https://www.labs.righthandrobotics.com/reflexhand&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ReFlex TakkTile hand&lt;/a&gt; working in Gazebo. The URDF provided by RightHand robotics was intended only for visualization in rviz. I added inertial and collision models, joint hardware interfaces, Gazebo materials for mesh rendering, and replaced the parallel kinematic structure in the fingers with a serial structure. I elaborate a bit on this process on this &lt;a href=&#34;https://github.com/RightHandRobotics/reflex-ros-pkg/issues/38&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Github issue&lt;/a&gt;. These changes can be found &lt;a href=&#34;https://bitbucket.org/robot-learning/ll4ma_robots_description/src/main/urdf/reflex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt; and allow basic actuation of the ReFlex hand:

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/2HQql-W8Lys&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;I added &lt;a href=&#34;http://gazebosim.org/tutorials?tut=contact_sensor&amp;amp;cat=sensors&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;contact sensors&lt;/a&gt; to the fingers to mimic the contact sensing offered by the real hand. Thank you to &lt;a href=&#34;https://mabelzhang.wordpress.com/bio/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mabel Zhang&lt;/a&gt; for her advice in setting this up! Here is a video of contacts being detected by the ReFlex hand in Gazebo using the contact sensor plugin (each green square is a separate contact sensor):&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/oEuwmzLlE84&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;
&lt;p&gt;I have also extended the basic contact sensing to also detect continuous pressure values. These are not yet fully functional yet though as they are not scaled correctly to the real hand. This is still an active area for development. I am also interested in eventually modeling the underactuated joints, and our lab is looking into the best way to handle this in Gazebo.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
